{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import glob as gb\n",
    "import pyyolo\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import darknet\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = rs.pipeline()  #接收相机信息\n",
    "config = rs.config()      #相机信息配置\n",
    "config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)   #848*480\n",
    "config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 30)\n",
    "\n",
    "profile = pipeline.start(config)   #打开相机\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()   #检索深度图的单位和meters单位之间的映射 (深度比例)\n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)  #执行深度图像与另一个图像之间的对其\n",
    "def get_aligned_imgs():\n",
    "    for i in range(50):\n",
    "        frames = pipeline.wait_for_frames()     #获取Realsense一帧的数据\n",
    "        aligned_frames = align.process(frames)   #在给定的帧上运行对齐过程，以获得一组对齐的帧\n",
    "\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        cv2.imwrite('/home/toke/Desktop/image/camera_catch.jpg', color_image)\n",
    "        cv2.imwrite('/home/toke/Desktop/image/camera_catch_depth.jpg', depth_image)\n",
    "    return color_image, depth_image\n",
    "color_image, depth_image = get_aligned_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4359, 4332, 4332, ...,  476,  475,  473],\n",
       "       [4387, 4387, 4332, ...,  476,  475,  473],\n",
       "       [4416, 4416, 4387, ...,  477,  476,  474],\n",
       "       ...,\n",
       "       [ 301,  301,  301, ...,  363,  363,  363],\n",
       "       [ 301,  301,  301, ...,  362,  362,  362],\n",
       "       [ 300,  300,  300, ...,  362,  362,  362]], dtype=uint16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyyolo.yolo.YOLO object at 0x7fcccb2647d0>\n",
      "[BBox([351, 136,  60, 131])]\n"
     ]
    }
   ],
   "source": [
    "testImg = '/home/toke/Desktop/image/camera_catch.jpg'\n",
    "### python3 run yolov4 model\n",
    "img = Image.open(testImg)   #PIL库的图片读取函数 （W x H 不含通道数）\n",
    "fname = os.path.basename(testImg)\n",
    "draw = ImageDraw.Draw(img)  #在图像上绘制一些东西\n",
    "image = cv2.imread(testImg) \n",
    "\n",
    "detector = pyyolo.YOLO(\"/home/toke/Packages/darknet/models/yolov4-custom.cfg\",\n",
    "                       \"/home/toke/Packages/darknet/models/yolov4-custom_45000_2020_0629.weights\",\n",
    "                       \"/home/toke/Packages/darknet/models/my_laji.data\",\n",
    "                       detection_threshold = 0.5,\n",
    "                       hier_threshold = 0.5,\n",
    "                       nms_threshold = 0.45)   \n",
    "#nms_threshold(非极大值抑制)\n",
    "print(detector)\n",
    "bboxes, center_points = [], []\n",
    "dets = detector.detect(image, rgb=False)\n",
    "print(dets)\n",
    "for i, det in enumerate(dets):\n",
    "    # print ('Detection:', {i}, {det})\n",
    "    xmin, ymin, xmax, ymax = det.to_xyxy()\n",
    "    bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "    center_point = (math.ceil((xmin + xmax) / 2), math.ceil((ymin + ymax) / 2))\n",
    "    draw.ellipse((center_point[0], center_point[1], center_point[0] + 20, center_point[1] + 20), 'red')\n",
    "\n",
    "bboxes = np.vstack(bbox)\n",
    "center_points = np.vstack(center_point)\n",
    "\n",
    "img.show()\n",
    "path = '/home/toke/Desktop'\n",
    "fname = os.path.basename(testImg)\n",
    "img.save(os.path.join(path, fname))\n",
    "\n",
    "#return bboxes, center_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pick, center_points = bboxes, center_point    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[351],\n",
       "       [136],\n",
       "       [411],\n",
       "       [267]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_crop = depth_image[int(bbox_pick[1]):int(bbox_pick[3]), int(bbox_pick[0]):int(bbox_pick[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4359, 4332, 4332, ...,  476,  475,  473],\n",
       "       [4387, 4387, 4332, ...,  476,  475,  473],\n",
       "       [4416, 4416, 4387, ...,  477,  476,  474],\n",
       "       ...,\n",
       "       [ 301,  301,  301, ...,  363,  363,  363],\n",
       "       [ 301,  301,  301, ...,  362,  362,  362],\n",
       "       [ 300,  300,  300, ...,  362,  362,  362]], dtype=uint16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_crop, alpha=0.03), cv2.COLORMAP_JET)\n",
    "cv2.imshow(\"cropped depth\", crop_colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 2950, 2950, 2963],\n",
       "       [   0,    0,    0, ..., 2950, 2950, 2950],\n",
       "       [   0,    0,    0, ..., 2925, 2925, 2925],\n",
       "       ...,\n",
       "       [ 837,  837,  834, ...,  858,  858,  865],\n",
       "       [ 835,  835,  834, ...,  858,  858,  865],\n",
       "       [ 835,  835,  833, ...,  858,  858,  866]], dtype=uint16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y=depth_crop.tolist()\n",
    "y = depth_crop.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7860, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KMeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8f1754720230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mk_silhouette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 自定义函数的调用（指定原始数据和选取范围）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-8f1754720230>\u001b[0m in \u001b[0;36mk_silhouette\u001b[0;34m(X, clusters)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KMeans' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "# 构造自定义函数，用于绘制不同k值和对应轮廓系数的折线图\n",
    "def k_silhouette(X, clusters):\n",
    "    K = range(2,clusters+1)\n",
    "# 构建空列表，用于存储个中簇数下的轮廓系数\n",
    "    S = []\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(X)\n",
    "        labels = kmeans.labels_\n",
    "        S.append(metrics.silhouette_score(X, labels, metric='euclidean'))  # 调用字模块metrics中的silhouette_score函数，计算轮廓系数\n",
    "   \n",
    "    plt.rcParams['font.sans-serif'] = ['KaiTi', 'SimHei', 'FangSong']# 中文和负号的正常显示\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    plt.style.use('ggplot')# 设置绘图风格\n",
    "    \n",
    "    plt.plot(K, S, 'b*-')  # 绘制K的个数与轮廓系数的关系\n",
    "    plt.xlabel('the number of chu')\n",
    "    plt.ylabel('lun kuo xi shu')\n",
    "    \n",
    "    plt.show() # 显示图形\n",
    "\n",
    "\n",
    "k_silhouette(y, 50)# 自定义函数的调用（指定原始数据和选取范围）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "for k in range(2,5):\n",
    "    clf = KMeans(n_clusters=k) #设定k  ！！！！！！！！！！这里就是调用KMeans算法\n",
    "    s = clf.fit(y) #加载数据集合\n",
    "    numSamples = len(y) \n",
    "    centroids = clf.labels_\n",
    "    print (centroids,type(centroids)) #显示中心点\n",
    "    print (clf.inertia_)  #显示聚类效果 评价指标\n",
    "    mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "    #画出所有样例点 属于同一分类的绘制同样的颜色\n",
    "    for i in range(numSamples):\n",
    "        #markIndex = int(clusterAssment[i, 0])\n",
    "        plt.plot(y[i][0], 0, mark[clf.labels_[i]]) #mark[markIndex])\n",
    "    mark = ['Dr', 'Db', 'Dg', 'Dk', '^b', '+b', 'sb', 'db', '<b', 'pb']\n",
    "    # 画出质点，用特殊图型\n",
    "    centroids =  clf.cluster_centers_\n",
    "    for i in range(k):\n",
    "        plt.plot(centroids[i][0], 0, mark[i], markersize = 12)\n",
    "        #print centroids[i, 0], centroids[i, 1]\n",
    "        plt.axvline(centroids[i][0], ymin=0.3, ymax=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image[460][447]\n",
    "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_image[int(bbox_pick[0])][int(bbox_pick[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pick[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCoM(dpt):   #计算质心\n",
    "    \"\"\"\n",
    "    Calculate the center of mass\n",
    "    :param dpt: depth image\n",
    "    :return: (x,y,z) center of mass\n",
    "    \"\"\"\n",
    "\n",
    "    dc = dpt.copy()\n",
    "    dc[dc < 0] = 0\n",
    "    dc[dc > 10000] = 0\n",
    "    cc = ndimage.measurements.center_of_mass(dc > 0)\n",
    "    print ('cc:', cc)\n",
    "    num = np.count_nonzero(dc)\n",
    "    com = np.array((cc[1]*num, cc[0]*num, dc.sum()), np.float)\n",
    "\n",
    "    if num == 0:\n",
    "        return np.array((0, 0, 0), np.float)\n",
    "    else:\n",
    "        return com/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_center = calculateCoM(depth_crop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = depth_crop[int((mass_center[0]-5)):int((mass_center[0]+5)), int((mass_center[1]-5)):int((mass_center[1]+5))]\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.zeros(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[2] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BBox([351, 136,  60, 131])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting an array element with a sequence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
